{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################ Load datasets ################\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the train and test datasets to create two DataFrames\n",
    "train_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/train.csv\"\n",
    "train = pd.read_csv(train_url)\n",
    "\n",
    "test_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/test.csv\"\n",
    "test = pd.read_csv(test_url)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################ Basic Manipulations & Preliminary Analysis ################\n",
    "\n",
    "# Passengers that survived vs passengers that passed away\n",
    "print(train['Survived'].value_counts())\n",
    "\n",
    "tot = len(train.index)\n",
    "surv = train['Survived'].sum()\n",
    "dead = train['Survived'].loc[train['Survived']==0].count()\n",
    "print(surv/dead)\n",
    "# Equiv print(surv/(tot-surv))\n",
    "\n",
    "print(train['Survived'].loc[ (train['Sex']=='male') & (train['Survived']==1) ].value_counts())\n",
    "\n",
    "# As proportions\n",
    "print(train[\"Survived\"].value_counts(normalize=True))\n",
    "\n",
    "# Males that survived vs males that passed away\n",
    "print(train.groupby('Sex')['Survived'].value_counts())\n",
    "print(train.groupby('Sex')['Survived'].value_counts(normalize=True))\n",
    "\n",
    "# Add a column and affect value\n",
    "train['Child'] = float('NaN')\n",
    "train['Child'][train['Age']<18] = 1\n",
    "train['Child'][train['Age']>=18] = 0\n",
    "train['Child'].describe()\n",
    "\n",
    "# Plot survival rate given age bucket\n",
    "bins = np.linspace(0, train.Age.max(), 10)\n",
    "a = train['Survived'].groupby(np.digitize(train.Age, bins)).value_counts(normalize=True)\n",
    "a.unstack(level=1).plot(kind='bar', stacked=True, width = 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################ First Tree ################\n",
    "\n",
    "######### train set #########\n",
    "\n",
    "# Convert the male and female groups to integer form\n",
    "train[\"Sex\"][train[\"Sex\"] == \"male\"] = 0\n",
    "train[\"Sex\"][train[\"Sex\"] == \"female\"] = 1\n",
    "\n",
    "# Impute the Embarked variable\n",
    "train[\"Embarked\"] = train[\"Embarked\"].fillna('S')\n",
    "\n",
    "# Convert the Embarked classes to integer form\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"S\"] = 0\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"C\"] = 1\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"Q\"] = 2\n",
    "\n",
    "# Fill NaN Age values with median\n",
    "train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())\n",
    "\n",
    "# Create the target and features numpy arrays: target, features_one\n",
    "target = train['Survived'].values\n",
    "features_one = train[[\"Pclass\", \"Sex\", \"Age\", \"Fare\"]].values\n",
    "\n",
    "# Fit your first decision tree: my_tree_one\n",
    "from sklearn import tree\n",
    "my_tree_one = tree.DecisionTreeClassifier()\n",
    "my_tree_one = my_tree_one.fit(features_one, target)\n",
    "\n",
    "# Look at the importance and score of the included features\n",
    "print(my_tree_one.feature_importances_)\n",
    "print(my_tree_one.score(features_one, target))\n",
    "\n",
    "\n",
    "######### test set #########\n",
    "\n",
    "# Fill missing value with the median\n",
    "test.Fare = test.Fare.fillna(test.Fare.median())\n",
    "# Alernative : test['Fare'] = test['Fare'].fillna(test['Fare'].median())\n",
    "test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].median())\n",
    "test[\"Sex\"][test[\"Sex\"] == \"male\"] = 0\n",
    "test[\"Sex\"][test[\"Sex\"] == \"female\"] = 1\n",
    "\n",
    "# Extract the features from the test set: Pclass, Sex, Age, and Fare.\n",
    "test_features = test[[\"Pclass\", \"Sex\", \"Age\", \"Fare\"]].values\n",
    "\n",
    "test[[\"Pclass\", \"Sex\", \"Age\", \"Fare\"]].describe()\n",
    "\n",
    "# Make your prediction using the test set\n",
    "my_prediction = my_tree_one.predict(test_features)\n",
    "\n",
    "# Create a data frame with two columns: PassengerId & Survived. Survived contains your predictions\n",
    "PassengerId = np.array(test[\"PassengerId\"]).astype(int)\n",
    "my_solution = pd.DataFrame(my_prediction, PassengerId, columns = [\"Survived\"])\n",
    "\n",
    "# Write your solution to a csv file with the name my_solution.csv\n",
    "my_solution.to_csv(\"my_solution_one.csv\", index_label = [\"PassengerId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################ Second Tree : Regularization ################\n",
    "\n",
    "train[[\"Pclass\",\"Age\",\"Sex\",\"Fare\", 'SibSp', 'Parch', 'Embarked']].describe()\n",
    "\n",
    "# Create a new array with the added features: features_two\n",
    "features_two = train[[\"Pclass\",\"Age\",\"Sex\",\"Fare\", 'SibSp', 'Parch', 'Embarked']].values\n",
    "\n",
    "# Control overfitting by setting \"max_depth\" to 10 and \"min_samples_split\" to 5 : my_tree_two\n",
    "max_depth = 10\n",
    "min_samples_split = 5\n",
    "my_tree_two = tree.DecisionTreeClassifier(max_depth = max_depth, min_samples_split = min_samples_split, random_state = 1)\n",
    "my_tree_two = my_tree_two.fit(features_two, target)\n",
    "\n",
    "# Look at the importance and score of the included features\n",
    "print(my_tree_two.feature_importances_)\n",
    "print(my_tree_two.score(features_two, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################ Third Tree : Feature-engineering ################\n",
    "\n",
    "# Create train_two with the newly defined feature\n",
    "train_two = train.copy()\n",
    "train_two[\"family_size\"] = train_two[\"SibSp\"]+train_two[\"Parch\"]+1\n",
    "\n",
    "# Create a new feature set and add the new feature\n",
    "features_three = train_two[[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"SibSp\", \"Parch\", \"family_size\"]].values\n",
    "\n",
    "# Define the tree classifier, then fit the model\n",
    "my_tree_three = tree.DecisionTreeClassifier()\n",
    "my_tree_three = my_tree_three.fit(features_three, target)\n",
    "\n",
    "# Print the score of this decision tree\n",
    "print(my_tree_three.score(features_three, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################ Random Forest ################\n",
    "\n",
    "# Import the `RandomForestClassifier`\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# We want the Pclass, Age, Sex, Fare,SibSp, Parch, and Embarked variables\n",
    "features_forest = train[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values\n",
    "\n",
    "# Building and fitting my_forest\n",
    "forest = RandomForestClassifier(max_depth = 10, min_samples_split=2, n_estimators = 100, random_state = 1)\n",
    "my_forest = forest.fit(features_forest, target)\n",
    "\n",
    "# Print the score of the fitted random forest\n",
    "print(my_forest.score(features_forest, target))\n",
    "\n",
    "# Compute predictions on our test set features\n",
    "test[\"Embarked\"][test[\"Embarked\"] == \"S\"] = 0\n",
    "test[\"Embarked\"][test[\"Embarked\"] == \"C\"] = 1\n",
    "test[\"Embarked\"][test[\"Embarked\"] == \"Q\"] = 2\n",
    "test_features = test[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values\n",
    "pred_forest = my_forest.predict(test_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
